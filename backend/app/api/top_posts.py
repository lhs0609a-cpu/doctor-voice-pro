"""
ìƒìœ„ ê¸€ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸
ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ 1~3ìœ„ ê¸€ë“¤ì„ ë¶„ì„í•˜ê³  ê¸€ì“°ê¸° ê°€ì´ë“œ ì œê³µ
"""

import asyncio
from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func
from typing import Optional, List
from pydantic import BaseModel

from app.api.deps import get_db
from app.models.top_post_analysis import TopPostAnalysis, AggregatedPattern
from app.models.analysis_job import AnalysisJob, CollectedKeyword
from app.services.top_post_analyzer import (
    analyze_top_posts,
    generate_writing_guide,
    generate_ai_prompt_guide,
    CATEGORIES,
    detect_category
)
from app.services.keyword_collector import (
    collect_keywords_for_category,
    get_all_categories,
    get_category_keyword_stats,
    CATEGORY_SEEDS
)
from app.services.bulk_analysis_service import (
    BulkAnalysisService,
    run_bulk_analysis,
    get_analysis_dashboard,
    get_category_rules
)

router = APIRouter()


class AnalyzeRequest(BaseModel):
    """ë¶„ì„ ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    keyword: str
    top_n: int = 3


class AnalyzeResponse(BaseModel):
    """ë¶„ì„ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    keyword: str
    category: str
    category_name: str
    analyzed_count: int
    results: list
    summary: Optional[dict] = None
    error: Optional[str] = None


@router.post("/analyze", response_model=AnalyzeResponse)
async def analyze_keyword(
    request: AnalyzeRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    í‚¤ì›Œë“œì— ëŒ€í•œ ìƒìœ„ ê¸€ ë¶„ì„

    - ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ 1~3ìœ„ ê¸€ì„ ìˆ˜ì§‘
    - ê° ê¸€ì˜ ì œëª©, ë³¸ë¬¸, ì´ë¯¸ì§€ ë“± ë¶„ì„
    - ê²°ê³¼ë¥¼ DBì— ì €ì¥í•˜ê³  ìš”ì•½ í†µê³„ ë°˜í™˜
    """
    try:
        # ë™ê¸° DB ì„¸ì…˜ìœ¼ë¡œ ë³€í™˜ í•„ìš” - ì¼ë‹¨ Noneìœ¼ë¡œ ì „ë‹¬
        result = await analyze_top_posts(
            keyword=request.keyword,
            top_n=request.top_n,
            db=None  # ë¹„ë™ê¸° í™˜ê²½ì—ì„œëŠ” ë³„ë„ ì²˜ë¦¬ í•„ìš”
        )

        return AnalyzeResponse(**result)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/patterns/{category}")
async def get_patterns(
    category: str,
    db: AsyncSession = Depends(get_db)
):
    """
    ì¹´í…Œê³ ë¦¬ë³„ ì¶•ì ëœ íŒ¨í„´ ì¡°íšŒ
    """
    result = await db.execute(
        select(AggregatedPattern).where(AggregatedPattern.category == category)
    )
    patterns = result.scalar_one_or_none()

    if not patterns:
        return {
            "category": category,
            "sample_count": 0,
            "message": "í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
        }

    return {
        "category": category,
        "category_name": CATEGORIES.get(category, {}).get("name", "ì¼ë°˜"),
        "sample_count": patterns.sample_count,
        "patterns": {
            "title": {
                "avg_length": round(patterns.avg_title_length),
                "keyword_rate": round(patterns.title_keyword_rate * 100, 1),
                "keyword_position": {
                    "front": round(patterns.keyword_position_front * 100, 1),
                    "middle": round(patterns.keyword_position_middle * 100, 1),
                    "end": round(patterns.keyword_position_end * 100, 1)
                }
            },
            "content": {
                "avg_length": round(patterns.avg_content_length),
                "min_length": patterns.min_content_length,
                "max_length": patterns.max_content_length,
                "avg_headings": round(patterns.avg_heading_count, 1),
                "avg_keyword_count": round(patterns.avg_keyword_count, 1),
                "avg_keyword_density": round(patterns.avg_keyword_density, 2)
            },
            "media": {
                "avg_images": round(patterns.avg_image_count, 1),
                "min_images": patterns.min_image_count,
                "max_images": patterns.max_image_count,
                "video_usage_rate": round(patterns.video_usage_rate * 100, 1)
            },
            "extras": {
                "map_usage_rate": round(patterns.map_usage_rate * 100, 1)
            }
        },
        "updated_at": patterns.updated_at.isoformat() if patterns.updated_at else None
    }


@router.get("/writing-guide")
async def get_writing_guide(
    category: str = Query(default="general", description="ì¹´í…Œê³ ë¦¬"),
    keyword: Optional[str] = Query(default=None, description="í‚¤ì›Œë“œ (ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€)"),
    db: AsyncSession = Depends(get_db)
):
    """
    ê¸€ì“°ê¸° ê°€ì´ë“œ ì¡°íšŒ

    - ì¶•ì ëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìµœì í™”ëœ ê¸€ì“°ê¸° ê·œì¹™ ë°˜í™˜
    - ë°ì´í„° ë¶€ì¡± ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
    """
    # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€
    if keyword:
        category = detect_category(keyword)

    # íŒ¨í„´ ì¡°íšŒ
    result = await db.execute(
        select(AggregatedPattern).where(AggregatedPattern.category == category)
    )
    patterns = result.scalar_one_or_none()

    # ê¸°ë³¸ ê·œì¹™
    DEFAULT_RULES = {
        "title": {
            "length": {"optimal": 30, "min": 20, "max": 45},
            "keyword_placement": {
                "include_keyword": True,
                "rate": 80,
                "best_position": "front",
                "position_distribution": {"front": 60, "middle": 30, "end": 10}
            }
        },
        "content": {
            "length": {"optimal": 2000, "min": 1500, "max": 3500},
            "structure": {
                "heading_count": {"optimal": 5, "min": 3, "max": 8},
                "keyword_density": {"optimal": 1.2, "min": 0.8, "max": 2.0},
                "keyword_count": {"optimal": 8, "min": 5, "max": 15}
            }
        },
        "media": {
            "images": {"optimal": 10, "min": 5, "max": 15},
            "videos": {"usage_rate": 20, "recommended": False}
        },
        "extras": {
            "map": {"usage_rate": 15, "recommended": False},
            "quote": {"usage_rate": 30, "recommended": True},
            "list": {"usage_rate": 40, "recommended": True}
        }
    }

    if not patterns or patterns.sample_count < 3:
        return {
            "status": "insufficient_data",
            "confidence": 0,
            "sample_count": patterns.sample_count if patterns else 0,
            "category": category,
            "category_name": CATEGORIES.get(category, {}).get("name", "ì¼ë°˜"),
            "message": "ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. 'ë„¤ì´ë²„ ìƒìœ„ë…¸ì¶œ' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.",
            "rules": DEFAULT_RULES
        }

    sample_count = patterns.sample_count
    confidence = min(1.0, sample_count / 30)

    # ìµœì  í‚¤ì›Œë“œ ìœ„ì¹˜ ê²°ì •
    positions = {
        "front": patterns.keyword_position_front,
        "middle": patterns.keyword_position_middle,
        "end": patterns.keyword_position_end
    }
    best_position = max(positions, key=positions.get)

    return {
        "status": "data_driven",
        "confidence": round(confidence, 2),
        "sample_count": sample_count,
        "category": category,
        "category_name": CATEGORIES.get(category, {}).get("name", "ì¼ë°˜"),
        "rules": {
            "title": {
                "length": {
                    "optimal": round(patterns.avg_title_length),
                    "min": max(15, round(patterns.avg_title_length * 0.7)),
                    "max": min(60, round(patterns.avg_title_length * 1.3))
                },
                "keyword_placement": {
                    "include_keyword": patterns.title_keyword_rate > 0.5,
                    "rate": round(patterns.title_keyword_rate * 100, 1),
                    "best_position": best_position,
                    "position_distribution": {
                        "front": round(patterns.keyword_position_front * 100, 1),
                        "middle": round(patterns.keyword_position_middle * 100, 1),
                        "end": round(patterns.keyword_position_end * 100, 1)
                    }
                }
            },
            "content": {
                "length": {
                    "optimal": round(patterns.avg_content_length),
                    "min": max(500, round(patterns.avg_content_length * 0.7)),
                    "max": round(patterns.avg_content_length * 1.3)
                },
                "structure": {
                    "heading_count": {
                        "optimal": round(patterns.avg_heading_count),
                        "min": max(2, round(patterns.avg_heading_count * 0.6)),
                        "max": round(patterns.avg_heading_count * 1.5)
                    },
                    "keyword_density": {
                        "optimal": round(patterns.avg_keyword_density, 2),
                        "min": max(0.3, round(patterns.avg_keyword_density * 0.5, 2)),
                        "max": min(3.0, round(patterns.avg_keyword_density * 1.5, 2))
                    },
                    "keyword_count": {
                        "optimal": round(patterns.avg_keyword_count),
                        "min": max(3, round(patterns.avg_keyword_count * 0.6)),
                        "max": round(patterns.avg_keyword_count * 1.4)
                    }
                }
            },
            "media": {
                "images": {
                    "optimal": round(patterns.avg_image_count),
                    "min": max(3, patterns.min_image_count),
                    "max": patterns.max_image_count
                },
                "videos": {
                    "usage_rate": round(patterns.video_usage_rate * 100, 1),
                    "recommended": patterns.video_usage_rate > 0.3
                }
            },
            "extras": {
                "map": {
                    "usage_rate": round(patterns.map_usage_rate * 100, 1),
                    "recommended": patterns.map_usage_rate > 0.2
                },
                "quote": {"usage_rate": 30, "recommended": True},
                "list": {"usage_rate": 40, "recommended": True}
            }
        }
    }


@router.get("/writing-guide/prompt")
async def get_writing_guide_prompt(
    category: str = Query(default="general", description="ì¹´í…Œê³ ë¦¬"),
    keyword: Optional[str] = Query(default=None, description="í‚¤ì›Œë“œ"),
    db: AsyncSession = Depends(get_db)
):
    """
    AI í”„ë¡¬í”„íŠ¸ìš© ê¸€ì“°ê¸° ê°€ì´ë“œ í…ìŠ¤íŠ¸ ë°˜í™˜

    - ë¸”ë¡œê·¸ ìƒì„± ì‹œ AI í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  ìµœì í™” ê·œì¹™ í…ìŠ¤íŠ¸
    """
    # ê°€ì´ë“œ ì¡°íšŒ
    guide = await get_writing_guide(category=category, keyword=keyword, db=db)

    rules = guide["rules"]

    prompt = f"""[ìƒìœ„ë…¸ì¶œ ìµœì í™” ê·œì¹™ - {guide.get('sample_count', 0)}ê°œ ê¸€ ë¶„ì„ ê¸°ë°˜, ì‹ ë¢°ë„ {guide.get('confidence', 0) * 100:.0f}%]

## ì œëª© ê·œì¹™
- ê¸€ì ìˆ˜: {rules['title']['length']['min']}~{rules['title']['length']['max']}ì (ìµœì : {rules['title']['length']['optimal']}ì)
- í‚¤ì›Œë“œ ìœ„ì¹˜: {rules['title']['keyword_placement']['best_position']} (ì•:{rules['title']['keyword_placement']['position_distribution']['front']}% ì¤‘ê°„:{rules['title']['keyword_placement']['position_distribution']['middle']}% ë:{rules['title']['keyword_placement']['position_distribution']['end']}%)
- í‚¤ì›Œë“œ í¬í•¨ë¥ : {rules['title']['keyword_placement']['rate']}%

## ë³¸ë¬¸ ê·œì¹™
- ê¸€ì ìˆ˜: {rules['content']['length']['min']}~{rules['content']['length']['max']}ì (ìµœì : {rules['content']['length']['optimal']}ì)
- ì†Œì œëª©: {rules['content']['structure']['heading_count']['min']}~{rules['content']['structure']['heading_count']['max']}ê°œ
- í‚¤ì›Œë“œ ë“±ì¥: {rules['content']['structure']['keyword_count']['min']}~{rules['content']['structure']['keyword_count']['max']}íšŒ
- í‚¤ì›Œë“œ ë°€ë„: {rules['content']['structure']['keyword_density']['min']}~{rules['content']['structure']['keyword_density']['max']}/1000ì

## ì´ë¯¸ì§€ ê·œì¹™
- ì´ë¯¸ì§€: {rules['media']['images']['min']}~{rules['media']['images']['max']}ì¥ (ìµœì : {rules['media']['images']['optimal']}ì¥)

ì´ ê·œì¹™ì„ ë”°ë¼ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    return {
        "category": category,
        "category_name": guide.get("category_name", "ì¼ë°˜"),
        "sample_count": guide.get("sample_count", 0),
        "confidence": guide.get("confidence", 0),
        "prompt": prompt
    }


@router.get("/stats")
async def get_analysis_stats(db: AsyncSession = Depends(get_db)):
    """
    ì „ì²´ ë¶„ì„ í†µê³„ ì¡°íšŒ
    """
    # ì „ì²´ ë¶„ì„ ìˆ˜
    total_result = await db.execute(
        select(func.count(TopPostAnalysis.id))
    )
    total_count = total_result.scalar() or 0

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ìˆ˜
    category_stats = {}
    for cat_id in CATEGORIES.keys():
        cat_result = await db.execute(
            select(func.count(TopPostAnalysis.id)).where(
                TopPostAnalysis.category == cat_id
            )
        )
        count = cat_result.scalar() or 0
        if count > 0:
            category_stats[cat_id] = {
                "name": CATEGORIES[cat_id]["name"],
                "count": count
            }

    # ìµœê·¼ ë¶„ì„ (ìµœê·¼ 10ê°œ)
    recent_result = await db.execute(
        select(TopPostAnalysis)
        .order_by(TopPostAnalysis.analyzed_at.desc())
        .limit(10)
    )
    recent_analyses = recent_result.scalars().all()

    recent_list = []
    for analysis in recent_analyses:
        recent_list.append({
            "keyword": analysis.keyword,
            "rank": analysis.rank,
            "title": analysis.title[:50] + "..." if analysis.title and len(analysis.title) > 50 else analysis.title,
            "category": analysis.category,
            "analyzed_at": analysis.analyzed_at.isoformat() if analysis.analyzed_at else None
        })

    return {
        "total_analyses": total_count,
        "category_breakdown": category_stats,
        "recent_analyses": recent_list
    }


@router.get("/categories")
async def get_categories():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ
    """
    return {
        "categories": [
            {"id": cat_id, "name": cat_info["name"], "keywords": cat_info["keywords"][:5]}
            for cat_id, cat_info in CATEGORIES.items()
        ]
    }


# ============================================================
# ëŒ€ëŸ‰ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸
# ============================================================

class BulkAnalyzeRequest(BaseModel):
    """ëŒ€ëŸ‰ ë¶„ì„ ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    category: str
    target_count: int = 100  # 100, 500, 1000
    keywords: Optional[List[str]] = None


class BulkAnalyzeResponse(BaseModel):
    """ëŒ€ëŸ‰ ë¶„ì„ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    job_id: str
    category: str
    target_count: int
    status: str
    message: str


@router.post("/bulk-analyze", response_model=BulkAnalyzeResponse)
async def start_bulk_analysis(
    request: BulkAnalyzeRequest,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db)
):
    """
    ëŒ€ëŸ‰ ë¶„ì„ ì‘ì—… ì‹œì‘

    - ì¹´í…Œê³ ë¦¬ì™€ ëª©í‘œ ë¶„ì„ ìˆ˜ë¥¼ ì§€ì •í•˜ì—¬ ëŒ€ëŸ‰ ë¶„ì„ ì‹œì‘
    - ë°±ê·¸ë¼ìš´ë“œì—ì„œ í‚¤ì›Œë“œ ìˆ˜ì§‘ ë° ìƒìœ„ê¸€ ë¶„ì„ ì‹¤í–‰
    - ì‘ì—… IDë¥¼ ë°˜í™˜í•˜ì—¬ ì§„í–‰ ìƒí™© ì¡°íšŒ ê°€ëŠ¥
    """
    # ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ì¸ì§€ í™•ì¸
    if request.category not in CATEGORY_SEEDS:
        raise HTTPException(status_code=400, detail=f"Invalid category: {request.category}")

    # ëª©í‘œ ìˆ˜ ê²€ì¦
    if request.target_count not in [100, 500, 1000]:
        raise HTTPException(status_code=400, detail="target_count must be 100, 500, or 1000")

    try:
        # ë™ê¸° ì„¸ì…˜ ìƒì„± (SQLiteëŠ” ë™ê¸° ì‘ì—… í•„ìš”)
        from app.db.database import SessionLocal
        sync_db = SessionLocal()

        try:
            # ì‘ì—… ìƒì„±
            service = BulkAnalysisService(sync_db)
            job = service.create_job(
                category=request.category,
                target_count=request.target_count,
                keywords=request.keywords
            )

            # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘
            background_tasks.add_task(
                run_bulk_analysis_wrapper,
                job.id,
                request.category,
                request.target_count
            )

            return BulkAnalyzeResponse(
                job_id=job.id,
                category=request.category,
                target_count=request.target_count,
                status="pending",
                message=f"ë¶„ì„ ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‘ì—… ID: {job.id}"
            )
        finally:
            sync_db.close()

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def run_bulk_analysis_wrapper(job_id: str, category: str, target_count: int):
    """ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì‹¤í–‰ ë˜í¼"""
    from app.db.database import SessionLocal
    db = SessionLocal()
    try:
        await run_bulk_analysis(db, job_id, category, target_count)
    finally:
        db.close()


@router.get("/jobs")
async def get_analysis_jobs(
    category: Optional[str] = None,
    status: Optional[str] = None,
    limit: int = Query(default=20, le=100),
    db: AsyncSession = Depends(get_db)
):
    """
    ë¶„ì„ ì‘ì—… ëª©ë¡ ì¡°íšŒ
    """
    query = select(AnalysisJob)

    if category:
        query = query.where(AnalysisJob.category == category)
    if status:
        query = query.where(AnalysisJob.status == status)

    query = query.order_by(AnalysisJob.created_at.desc()).limit(limit)

    result = await db.execute(query)
    jobs = result.scalars().all()

    return {
        "jobs": [
            {
                "id": job.id,
                "category": job.category,
                "category_name": CATEGORY_SEEDS.get(job.category, {}).get("name", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "target_count": job.target_count,
                "status": job.status,
                "progress": job.progress,
                "keywords_collected": job.keywords_collected,
                "posts_analyzed": job.posts_analyzed,
                "error_message": job.error_message,
                "created_at": job.created_at.isoformat() if job.created_at else None,
                "completed_at": job.completed_at.isoformat() if job.completed_at else None
            }
            for job in jobs
        ]
    }


@router.get("/jobs/{job_id}")
async def get_job_status(
    job_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    ë¶„ì„ ì‘ì—… ìƒíƒœ ì¡°íšŒ
    """
    result = await db.execute(
        select(AnalysisJob).where(AnalysisJob.id == job_id)
    )
    job = result.scalar_one_or_none()

    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    return {
        "id": job.id,
        "category": job.category,
        "category_name": CATEGORY_SEEDS.get(job.category, {}).get("name", "ì•Œ ìˆ˜ ì—†ìŒ"),
        "target_count": job.target_count,
        "status": job.status,
        "progress": job.progress,
        "keywords_collected": job.keywords_collected,
        "keywords_total": job.keywords_total,
        "posts_analyzed": job.posts_analyzed,
        "posts_failed": job.posts_failed,
        "keywords": job.keywords[:20] if job.keywords else [],  # ìµœëŒ€ 20ê°œë§Œ ë°˜í™˜
        "error_message": job.error_message,
        "result_summary": job.result_summary,
        "created_at": job.created_at.isoformat() if job.created_at else None,
        "started_at": job.started_at.isoformat() if job.started_at else None,
        "completed_at": job.completed_at.isoformat() if job.completed_at else None
    }


@router.delete("/jobs/{job_id}")
async def cancel_job(
    job_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    ë¶„ì„ ì‘ì—… ì·¨ì†Œ
    """
    result = await db.execute(
        select(AnalysisJob).where(AnalysisJob.id == job_id)
    )
    job = result.scalar_one_or_none()

    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    if job.status not in ['pending', 'running']:
        raise HTTPException(status_code=400, detail="Cannot cancel completed or failed job")

    job.status = 'cancelled'
    await db.commit()

    return {"message": "Job cancelled successfully", "job_id": job_id}


@router.post("/collect-keywords")
async def collect_keywords(
    category: str = Query(..., description="ì¹´í…Œê³ ë¦¬ ID"),
    max_keywords: int = Query(default=100, le=500, description="ìµœëŒ€ ìˆ˜ì§‘ í‚¤ì›Œë“œ ìˆ˜")
):
    """
    ì—°ê´€ê²€ìƒ‰ì–´ ìˆ˜ì§‘

    - ì¹´í…Œê³ ë¦¬ì˜ ì‹œë“œ í‚¤ì›Œë“œì—ì„œ ì—°ê´€ê²€ìƒ‰ì–´ë¥¼ ìˆ˜ì§‘
    - ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ ëª©ë¡ ë°˜í™˜
    """
    if category not in CATEGORY_SEEDS:
        raise HTTPException(status_code=400, detail=f"Invalid category: {category}")

    try:
        result = await collect_keywords_for_category(category, max_keywords)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/keywords/{category}")
async def get_category_keywords(
    category: str,
    limit: int = Query(default=100, le=500),
    only_unanalyzed: bool = Query(default=False),
    db: AsyncSession = Depends(get_db)
):
    """
    ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ ì¡°íšŒ
    """
    if category not in CATEGORY_SEEDS:
        raise HTTPException(status_code=400, detail=f"Invalid category: {category}")

    query = select(CollectedKeyword).where(CollectedKeyword.category == category)

    if only_unanalyzed:
        query = query.where(CollectedKeyword.is_analyzed == 0)

    query = query.order_by(CollectedKeyword.created_at.desc()).limit(limit)

    result = await db.execute(query)
    keywords = result.scalars().all()

    return {
        "category": category,
        "category_name": CATEGORY_SEEDS[category]["name"],
        "total": len(keywords),
        "keywords": [
            {
                "keyword": kw.keyword,
                "source": kw.source,
                "is_analyzed": kw.is_analyzed == 1,
                "analysis_count": kw.analysis_count,
                "created_at": kw.created_at.isoformat() if kw.created_at else None
            }
            for kw in keywords
        ]
    }


@router.get("/dashboard")
async def get_dashboard(db: AsyncSession = Depends(get_db)):
    """
    ë¶„ì„ ëŒ€ì‹œë³´ë“œ í†µê³„

    - ì „ì²´ ë¶„ì„ í˜„í™©
    - ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    - ìµœê·¼ ì‘ì—… ëª©ë¡
    """
    # ì „ì²´ ë¶„ì„ ìˆ˜
    total_result = await db.execute(select(func.count(TopPostAnalysis.id)))
    total_posts = total_result.scalar() or 0

    # ì „ì²´ í‚¤ì›Œë“œ ìˆ˜
    keywords_result = await db.execute(select(func.count(CollectedKeyword.id)))
    total_keywords = keywords_result.scalar() or 0

    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    categories = []
    for cat_id, cat_info in CATEGORY_SEEDS.items():
        # ë¶„ì„ëœ ê¸€ ìˆ˜
        posts_result = await db.execute(
            select(func.count(TopPostAnalysis.id)).where(TopPostAnalysis.category == cat_id)
        )
        posts_count = posts_result.scalar() or 0

        # í‚¤ì›Œë“œ ìˆ˜
        kw_result = await db.execute(
            select(func.count(CollectedKeyword.id)).where(CollectedKeyword.category == cat_id)
        )
        kw_count = kw_result.scalar() or 0

        # íŒ¨í„´ ì¡°íšŒ
        pattern_result = await db.execute(
            select(AggregatedPattern).where(AggregatedPattern.category == cat_id)
        )
        pattern = pattern_result.scalar_one_or_none()

        categories.append({
            "category": cat_id,
            "category_name": cat_info["name"],
            "posts_count": posts_count,
            "keywords_count": kw_count,
            "sample_count": pattern.sample_count if pattern else 0,
            "confidence": round(min(1.0, (pattern.sample_count / 30)) if pattern else 0, 2),
            "last_updated": pattern.updated_at.isoformat() if pattern and pattern.updated_at else None
        })

    # ìƒ˜í”Œ ìˆ˜ ê¸°ì¤€ ì •ë ¬
    categories.sort(key=lambda x: x["sample_count"], reverse=True)

    # ìµœê·¼ ì‘ì—…
    jobs_result = await db.execute(
        select(AnalysisJob).order_by(AnalysisJob.created_at.desc()).limit(10)
    )
    jobs = jobs_result.scalars().all()

    return {
        "total_posts": total_posts,
        "total_keywords": total_keywords,
        "categories": categories,
        "recent_jobs": [
            {
                "id": job.id,
                "category": job.category,
                "category_name": CATEGORY_SEEDS.get(job.category, {}).get("name", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "target_count": job.target_count,
                "status": job.status,
                "progress": job.progress,
                "posts_analyzed": job.posts_analyzed,
                "created_at": job.created_at.isoformat() if job.created_at else None
            }
            for job in jobs
        ]
    }


@router.get("/rules/{category}")
async def get_rules(
    category: str,
    db: AsyncSession = Depends(get_db)
):
    """
    ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ëœ ê·œì¹™ ì¡°íšŒ

    - í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ìƒìœ„ê¸€ íŒ¨í„´ ê¸°ë°˜ ìµœì í™” ê·œì¹™ ë°˜í™˜
    - ê¸€ ìƒì„± ì‹œ ìë™ìœ¼ë¡œ ì ìš©ë¨
    """
    if category not in CATEGORY_SEEDS:
        raise HTTPException(status_code=400, detail=f"Invalid category: {category}")

    # íŒ¨í„´ ì¡°íšŒ
    result = await db.execute(
        select(AggregatedPattern).where(AggregatedPattern.category == category)
    )
    pattern = result.scalar_one_or_none()

    if not pattern or pattern.sample_count < 3:
        return {
            "status": "insufficient_data",
            "category": category,
            "category_name": CATEGORY_SEEDS[category]["name"],
            "sample_count": pattern.sample_count if pattern else 0,
            "message": "ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ëŒ€ëŸ‰ ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.",
            "rules": None
        }

    confidence = min(1.0, pattern.sample_count / 30)

    # ìµœì  í‚¤ì›Œë“œ ìœ„ì¹˜ ê²°ì •
    positions = {
        "front": pattern.keyword_position_front,
        "middle": pattern.keyword_position_middle,
        "end": pattern.keyword_position_end
    }
    best_position = max(positions, key=positions.get)

    return {
        "status": "data_driven",
        "category": category,
        "category_name": CATEGORY_SEEDS[category]["name"],
        "sample_count": pattern.sample_count,
        "confidence": round(confidence, 2),
        "rules": {
            "title": {
                "length": {
                    "optimal": round(pattern.avg_title_length),
                    "min": max(15, round(pattern.avg_title_length * 0.7)),
                    "max": min(60, round(pattern.avg_title_length * 1.3))
                },
                "keyword_placement": {
                    "include_keyword": pattern.title_keyword_rate > 0.5,
                    "rate": round(pattern.title_keyword_rate * 100, 1),
                    "best_position": best_position,
                    "position_distribution": {
                        "front": round(pattern.keyword_position_front * 100, 1),
                        "middle": round(pattern.keyword_position_middle * 100, 1),
                        "end": round(pattern.keyword_position_end * 100, 1)
                    }
                }
            },
            "content": {
                "length": {
                    "optimal": round(pattern.avg_content_length),
                    "min": max(500, round(pattern.avg_content_length * 0.7)),
                    "max": round(pattern.avg_content_length * 1.3)
                },
                "structure": {
                    "heading_count": {
                        "optimal": round(pattern.avg_heading_count),
                        "min": max(2, round(pattern.avg_heading_count * 0.6)),
                        "max": round(pattern.avg_heading_count * 1.5)
                    },
                    "keyword_density": {
                        "optimal": round(pattern.avg_keyword_density, 2),
                        "min": max(0.3, round(pattern.avg_keyword_density * 0.5, 2)),
                        "max": min(3.0, round(pattern.avg_keyword_density * 1.5, 2))
                    },
                    "keyword_count": {
                        "optimal": round(pattern.avg_keyword_count),
                        "min": max(3, round(pattern.avg_keyword_count * 0.6)),
                        "max": round(pattern.avg_keyword_count * 1.4)
                    }
                }
            },
            "media": {
                "images": {
                    "optimal": round(pattern.avg_image_count),
                    "min": max(3, pattern.min_image_count),
                    "max": pattern.max_image_count
                },
                "videos": {
                    "usage_rate": round(pattern.video_usage_rate * 100, 1),
                    "recommended": pattern.video_usage_rate > 0.3
                }
            }
        }
    }


@router.get("/analyzed-posts")
async def get_analyzed_posts(
    category: Optional[str] = Query(default=None, description="ì¹´í…Œê³ ë¦¬ í•„í„°"),
    keyword: Optional[str] = Query(default=None, description="í‚¤ì›Œë“œ ê²€ìƒ‰"),
    limit: int = Query(default=50, le=200, description="ì¡°íšŒ ê°œìˆ˜"),
    offset: int = Query(default=0, description="ì˜¤í”„ì…‹"),
    db: AsyncSession = Depends(get_db)
):
    """
    ë¶„ì„ëœ ê¸€ ëª©ë¡ ì¡°íšŒ

    - ìµœê·¼ ë¶„ì„ëœ ìƒìœ„ê¸€ ëª©ë¡ê³¼ ìƒì„¸ ì •ë³´ ë°˜í™˜
    - ì¹´í…Œê³ ë¦¬, í‚¤ì›Œë“œë¡œ í•„í„°ë§ ê°€ëŠ¥
    """
    query = select(TopPostAnalysis)

    if category:
        query = query.where(TopPostAnalysis.category == category)
    if keyword:
        query = query.where(TopPostAnalysis.keyword.contains(keyword))

    # ì „ì²´ ê°œìˆ˜
    count_query = select(func.count(TopPostAnalysis.id))
    if category:
        count_query = count_query.where(TopPostAnalysis.category == category)
    if keyword:
        count_query = count_query.where(TopPostAnalysis.keyword.contains(keyword))

    total_result = await db.execute(count_query)
    total_count = total_result.scalar() or 0

    # ëª©ë¡ ì¡°íšŒ
    query = query.order_by(TopPostAnalysis.analyzed_at.desc()).offset(offset).limit(limit)
    result = await db.execute(query)
    posts = result.scalars().all()

    # í‚¤ì›Œë“œë³„ ê·¸ë£¹í™” í†µê³„
    keyword_stats = {}
    for post in posts:
        kw = post.keyword
        if kw not in keyword_stats:
            keyword_stats[kw] = {
                "keyword": kw,
                "category": post.category,
                "posts_count": 0,
                "avg_content_length": 0,
                "avg_image_count": 0,
                "keyword_in_title_rate": 0,
                "posts": []
            }
        keyword_stats[kw]["posts_count"] += 1
        keyword_stats[kw]["avg_content_length"] += post.content_length
        keyword_stats[kw]["avg_image_count"] += post.image_count
        if post.title_has_keyword:
            keyword_stats[kw]["keyword_in_title_rate"] += 1
        keyword_stats[kw]["posts"].append({
            "id": post.id,
            "rank": post.rank,
            "title": post.title,
            "post_url": post.post_url,
            "content_length": post.content_length,
            "image_count": post.image_count,
            "video_count": post.video_count,
            "heading_count": post.heading_count,
            "keyword_count": post.keyword_count,
            "keyword_density": post.keyword_density,
            "has_map": post.has_map,
            "data_quality": post.data_quality,
            "analyzed_at": post.analyzed_at.isoformat() if post.analyzed_at else None
        })

    # í‰ê·  ê³„ì‚°
    for kw, stats in keyword_stats.items():
        n = stats["posts_count"]
        if n > 0:
            stats["avg_content_length"] = round(stats["avg_content_length"] / n)
            stats["avg_image_count"] = round(stats["avg_image_count"] / n, 1)
            stats["keyword_in_title_rate"] = round(stats["keyword_in_title_rate"] / n * 100, 1)

    return {
        "total_count": total_count,
        "returned_count": len(posts),
        "offset": offset,
        "limit": limit,
        "by_keyword": list(keyword_stats.values()),
        "posts": [
            {
                "id": post.id,
                "keyword": post.keyword,
                "rank": post.rank,
                "title": post.title,
                "post_url": post.post_url,
                "blog_id": post.blog_id,
                "category": post.category,
                "category_name": CATEGORY_SEEDS.get(post.category, {}).get("name", "ì¼ë°˜"),
                "content_length": post.content_length,
                "image_count": post.image_count,
                "video_count": post.video_count,
                "heading_count": post.heading_count,
                "keyword_count": post.keyword_count,
                "keyword_density": round(post.keyword_density, 2),
                "title_has_keyword": post.title_has_keyword,
                "title_keyword_position": post.title_keyword_position,
                "has_map": post.has_map,
                "has_quote": post.has_quote,
                "has_list": post.has_list,
                "data_quality": post.data_quality,
                "analyzed_at": post.analyzed_at.isoformat() if post.analyzed_at else None
            }
            for post in posts
        ]
    }


@router.get("/patterns-summary/{category}")
async def get_patterns_summary(
    category: str,
    db: AsyncSession = Depends(get_db)
):
    """
    ì¹´í…Œê³ ë¦¬ë³„ ë°œê²¬ëœ ê³µí†µì  ìš”ì•½

    - ìƒìœ„ê¸€ë“¤ì˜ ê³µí†µ íŒ¨í„´ì„ ìì—°ì–´ë¡œ ìš”ì•½
    - ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì œê³µ
    """
    if category not in CATEGORY_SEEDS:
        raise HTTPException(status_code=400, detail=f"Invalid category: {category}")

    # íŒ¨í„´ ì¡°íšŒ
    result = await db.execute(
        select(AggregatedPattern).where(AggregatedPattern.category == category)
    )
    pattern = result.scalar_one_or_none()

    if not pattern or pattern.sample_count < 3:
        return {
            "status": "insufficient_data",
            "category": category,
            "category_name": CATEGORY_SEEDS[category]["name"],
            "sample_count": pattern.sample_count if pattern else 0,
            "summary": None,
            "insights": []
        }

    # ìµœì  ìœ„ì¹˜ ê²°ì •
    positions = {
        "ì•ë¶€ë¶„": pattern.keyword_position_front,
        "ì¤‘ê°„": pattern.keyword_position_middle,
        "ë’·ë¶€ë¶„": pattern.keyword_position_end
    }
    best_position = max(positions, key=positions.get)

    # ì¸ì‚¬ì´íŠ¸ ìƒì„±
    insights = []

    # ì œëª© ê¸¸ì´ ì¸ì‚¬ì´íŠ¸
    insights.append({
        "category": "ì œëª©",
        "finding": f"í‰ê·  {round(pattern.avg_title_length)}ì",
        "recommendation": f"ì œëª©ì€ {max(15, round(pattern.avg_title_length * 0.7))}~{min(60, round(pattern.avg_title_length * 1.3))}ìê°€ ì ë‹¹í•©ë‹ˆë‹¤",
        "confidence": min(1.0, pattern.sample_count / 30)
    })

    # í‚¤ì›Œë“œ ìœ„ì¹˜ ì¸ì‚¬ì´íŠ¸
    if pattern.title_keyword_rate > 0.5:
        insights.append({
            "category": "ì œëª©",
            "finding": f"ìƒìœ„ê¸€ì˜ {round(pattern.title_keyword_rate * 100)}%ê°€ ì œëª©ì— í‚¤ì›Œë“œ í¬í•¨",
            "recommendation": f"í‚¤ì›Œë“œë¥¼ ì œëª©ì˜ {best_position}ì— ë°°ì¹˜í•˜ì„¸ìš”",
            "confidence": min(1.0, pattern.sample_count / 30)
        })

    # ë³¸ë¬¸ ê¸¸ì´ ì¸ì‚¬ì´íŠ¸
    insights.append({
        "category": "ë³¸ë¬¸",
        "finding": f"í‰ê·  {round(pattern.avg_content_length)}ì ({round(pattern.avg_content_length / 500)}ë¶„ ë¶„ëŸ‰)",
        "recommendation": f"ë³¸ë¬¸ì€ {max(500, round(pattern.avg_content_length * 0.7))}~{round(pattern.avg_content_length * 1.3)}ìê°€ ì ë‹¹í•©ë‹ˆë‹¤",
        "confidence": min(1.0, pattern.sample_count / 30)
    })

    # ì†Œì œëª© ì¸ì‚¬ì´íŠ¸
    if pattern.avg_heading_count > 0:
        insights.append({
            "category": "êµ¬ì¡°",
            "finding": f"í‰ê·  {round(pattern.avg_heading_count)}ê°œì˜ ì†Œì œëª© ì‚¬ìš©",
            "recommendation": f"ì†Œì œëª©ì„ {max(2, round(pattern.avg_heading_count * 0.6))}~{round(pattern.avg_heading_count * 1.5)}ê°œ ì‚¬ìš©í•˜ì„¸ìš”",
            "confidence": min(1.0, pattern.sample_count / 30)
        })

    # ì´ë¯¸ì§€ ì¸ì‚¬ì´íŠ¸
    insights.append({
        "category": "ì´ë¯¸ì§€",
        "finding": f"í‰ê·  {round(pattern.avg_image_count)}ì¥ ì‚¬ìš©",
        "recommendation": f"ì´ë¯¸ì§€ë¥¼ {max(3, pattern.min_image_count)}~{pattern.max_image_count}ì¥ ì‚½ì…í•˜ì„¸ìš”",
        "confidence": min(1.0, pattern.sample_count / 30)
    })

    # í‚¤ì›Œë“œ ë°€ë„ ì¸ì‚¬ì´íŠ¸
    insights.append({
        "category": "í‚¤ì›Œë“œ",
        "finding": f"1000ìë‹¹ í‰ê·  {round(pattern.avg_keyword_density, 1)}íšŒ ë“±ì¥",
        "recommendation": f"í‚¤ì›Œë“œë¥¼ ë³¸ë¬¸ì— {round(pattern.avg_keyword_count)}íšŒ ì •ë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ì„¸ìš”",
        "confidence": min(1.0, pattern.sample_count / 30)
    })

    # ì§€ë„ ì¸ì‚¬ì´íŠ¸
    if pattern.map_usage_rate > 0.2:
        insights.append({
            "category": "ë¶€ê°€ìš”ì†Œ",
            "finding": f"ìƒìœ„ê¸€ì˜ {round(pattern.map_usage_rate * 100)}%ê°€ ì§€ë„ ì‚¬ìš©",
            "recommendation": "ìœ„ì¹˜ ì •ë³´ê°€ ìˆë‹¤ë©´ ë„¤ì´ë²„ ì§€ë„ë¥¼ ì‚½ì…í•˜ì„¸ìš”",
            "confidence": min(1.0, pattern.sample_count / 30)
        })

    # ë™ì˜ìƒ ì¸ì‚¬ì´íŠ¸
    if pattern.video_usage_rate > 0.1:
        insights.append({
            "category": "ë¶€ê°€ìš”ì†Œ",
            "finding": f"ìƒìœ„ê¸€ì˜ {round(pattern.video_usage_rate * 100)}%ê°€ ë™ì˜ìƒ ì‚¬ìš©",
            "recommendation": "ê´€ë ¨ ë™ì˜ìƒì´ ìˆë‹¤ë©´ ì‚½ì…ì„ ê³ ë ¤í•˜ì„¸ìš”",
            "confidence": min(1.0, pattern.sample_count / 30)
        })

    # ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
    summary = f"""ã€{CATEGORY_SEEDS[category]['name']} ì¹´í…Œê³ ë¦¬ ìƒìœ„ê¸€ ë¶„ì„ ê²°ê³¼ã€‘
ë¶„ì„ ìƒ˜í”Œ: {pattern.sample_count}ê°œ ê¸€

ğŸ“ ì œëª©: í‰ê·  {round(pattern.avg_title_length)}ì, í‚¤ì›Œë“œëŠ” {best_position}ì— ë°°ì¹˜
ğŸ“„ ë³¸ë¬¸: í‰ê·  {round(pattern.avg_content_length)}ì
ğŸ–¼ï¸ ì´ë¯¸ì§€: í‰ê·  {round(pattern.avg_image_count)}ì¥
ğŸ“‘ ì†Œì œëª©: í‰ê·  {round(pattern.avg_heading_count)}ê°œ
ğŸ”‘ í‚¤ì›Œë“œ: ë³¸ë¬¸ì— í‰ê·  {round(pattern.avg_keyword_count)}íšŒ ë“±ì¥

ì´ íŒ¨í„´ì„ ë”°ë¥´ë©´ ìƒìœ„ë…¸ì¶œ í™•ë¥ ì´ ë†’ì•„ì§‘ë‹ˆë‹¤."""

    return {
        "status": "data_driven",
        "category": category,
        "category_name": CATEGORY_SEEDS[category]["name"],
        "sample_count": pattern.sample_count,
        "confidence": round(min(1.0, pattern.sample_count / 30), 2),
        "summary": summary,
        "insights": insights,
        "raw_patterns": {
            "title": {
                "avg_length": round(pattern.avg_title_length),
                "keyword_rate": round(pattern.title_keyword_rate * 100, 1),
                "best_position": best_position
            },
            "content": {
                "avg_length": round(pattern.avg_content_length),
                "avg_headings": round(pattern.avg_heading_count, 1),
                "avg_keyword_count": round(pattern.avg_keyword_count, 1),
                "avg_keyword_density": round(pattern.avg_keyword_density, 2)
            },
            "media": {
                "avg_images": round(pattern.avg_image_count, 1),
                "video_rate": round(pattern.video_usage_rate * 100, 1),
                "map_rate": round(pattern.map_usage_rate * 100, 1)
            }
        },
        "updated_at": pattern.updated_at.isoformat() if pattern.updated_at else None
    }


@router.get("/categories-with-stats")
async def get_categories_with_stats(db: AsyncSession = Depends(get_db)):
    """
    ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë° í†µê³„ ì¡°íšŒ
    """
    categories = []

    for cat_id, cat_info in CATEGORY_SEEDS.items():
        # ë¶„ì„ëœ ê¸€ ìˆ˜
        posts_result = await db.execute(
            select(func.count(TopPostAnalysis.id)).where(TopPostAnalysis.category == cat_id)
        )
        posts_count = posts_result.scalar() or 0

        # íŒ¨í„´ ì¡°íšŒ
        pattern_result = await db.execute(
            select(AggregatedPattern).where(AggregatedPattern.category == cat_id)
        )
        pattern = pattern_result.scalar_one_or_none()

        categories.append({
            "id": cat_id,
            "name": cat_info["name"],
            "seeds": cat_info["seeds"][:5],
            "posts_count": posts_count,
            "sample_count": pattern.sample_count if pattern else 0,
            "confidence": round(min(1.0, (pattern.sample_count / 30)) if pattern else 0, 2),
            "has_rules": pattern is not None and pattern.sample_count >= 3
        })

    return {"categories": categories}
